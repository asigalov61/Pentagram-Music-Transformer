{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pentagram Music Transformer Composer (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2023\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "gpy3qsulqHa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (GPU CHECK)"
      ],
      "metadata": {
        "id": "W_So4w8fqPGL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3rABEpKCO02",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title NVIDIA GPU check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (SETUP ENVIRONMENT)"
      ],
      "metadata": {
        "id": "C0XxnXGFqVyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK40g6V_BTNj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!git clone --depth 1 https://github.com/asigalov61/Pentagram-Music-Transformer\n",
        "!pip install huggingface_hub\n",
        "!pip install torch\n",
        "!pip install einops\n",
        "!pip install torch-summary\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzCOZU_gBiQV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import modules\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading core Pentagram Music Transformer modules...')\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import secrets\n",
        "import statistics\n",
        "import tqdm\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading main Pentagram Music Transformer modules...')\n",
        "import torch\n",
        "\n",
        "%cd /content/Pentagram-Music-Transformer\n",
        "\n",
        "import TMIDIX\n",
        "\n",
        "from nanoGPT import *\n",
        "\n",
        "%cd /content/\n",
        "print('=' * 70)\n",
        "print('Loading aux Pentagram Music Transformer modules...')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchsummary import summary\n",
        "from sklearn import metrics\n",
        "\n",
        "from midi2audio import FluidSynth\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('Enjoy! :)')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI3aQtHzqSnp"
      },
      "source": [
        "# (LOAD MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDquonbXC2je",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load Pentagram Music Transformer Small Model\n",
        "\n",
        "#@markdown Very fast 4k-fp16 model, 32 heads, 32 layers, 245k MIDIs training corpus\n",
        "\n",
        "full_path_to_model_checkpoint = \"/content/Pentagram-Music-Transformer/Models/Small/Pentagram_Music_Transformer_Small_Trained_Model_9986_steps_0.6707_loss_0.8031_acc.pth\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Model precision option\n",
        "\n",
        "model_precision = \"bfloat16\" # @param [\"bfloat16\", \"float16\", \"float32\"]\n",
        "\n",
        "#@markdown bfloat16 == Third precision/triple speed (if supported, otherwise the model will default to float16)\n",
        "\n",
        "#@markdown float16 == Half precision/double speed\n",
        "\n",
        "#@markdown float32 == Full precision/normal speed\n",
        "\n",
        "plot_tokens_embeddings = True # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading Pentagram Music Transformer Small Pre-Trained Model...')\n",
        "print('Please wait...')\n",
        "print('=' * 70)\n",
        "\n",
        "if os.path.isfile(full_path_to_model_checkpoint):\n",
        "  print('Model already exists...')\n",
        "\n",
        "else:\n",
        "  hf_hub_download(repo_id='asigalov61/Pentagram-Music-Transformer',\n",
        "                  filename='Pentagram_Music_Transformer_Small_Trained_Model_9986_steps_0.6707_loss_0.8031_acc.pth',\n",
        "                  local_dir='/content/Pentagram-Music-Transformer/Models/Small',\n",
        "                  local_dir_use_symlinks=False)\n",
        "\n",
        "print('=' * 70)\n",
        "print('Instantiating model...')\n",
        "print('=' * 70)\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
        "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
        "device_type = 'cuda'\n",
        "\n",
        "if model_precision == 'bfloat16' and torch.cuda.is_bf16_supported():\n",
        "  dtype = 'bfloat16'\n",
        "else:\n",
        "  dtype = 'float16'\n",
        "\n",
        "if model_precision == 'float16':\n",
        "  dtype = 'float16'\n",
        "\n",
        "if model_precision == 'float32':\n",
        "  dtype = 'float32'\n",
        "\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "ctx = torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "model_args = dict(n_layer=0, n_head=0, n_embd=0, block_size=0,\n",
        "                  bias=False, vocab_size=0, dropout=0, ignore_idx=1563) # start with model_args from command line\n",
        "\n",
        "checkpoint = torch.load(full_path_to_model_checkpoint, map_location='cuda')\n",
        "checkpoint_model_args = checkpoint['model_args']\n",
        "\n",
        "# force these config attributes to be equal otherwise we can't even resume training\n",
        "# the rest of the attributes (e.g. dropout) can stay as desired from command line\n",
        "\n",
        "for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:\n",
        "    model_args[k] = checkpoint_model_args[k]\n",
        "\n",
        "# create the model\n",
        "gptconf = GPTConfig(**model_args)\n",
        "model = GPT(gptconf)\n",
        "model = torch.nn.DataParallel(model)\n",
        "state_dict = checkpoint['model']\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading model checkpoint...')\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "iter_num = checkpoint['iter_num']\n",
        "best_val_loss = checkpoint['best_val_loss']\n",
        "print('=' * 70)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Model will use', dtype, 'precision')\n",
        "print('=' * 70)\n",
        "\n",
        "# Model stats\n",
        "print('Model summary:')\n",
        "summary(model)\n",
        "\n",
        "# Plot Token Embeddings\n",
        "if plot_tokens_embeddings:\n",
        "  tok_emb = model.module.transformer.wte.weight.detach().cpu().tolist()\n",
        "\n",
        "  cos_sim = metrics.pairwise_distances(\n",
        "    tok_emb, metric='cosine'\n",
        "  )\n",
        "  plt.figure(figsize=(7, 7))\n",
        "  plt.imshow(cos_sim, cmap=\"inferno\", interpolation=\"nearest\")\n",
        "  im_ratio = cos_sim.shape[0] / cos_sim.shape[1]\n",
        "  plt.colorbar(fraction=0.046 * im_ratio, pad=0.04)\n",
        "  plt.xlabel(\"Position\")\n",
        "  plt.ylabel(\"Position\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot()\n",
        "  plt.savefig(\"/content/Pentagram-Music-Transformer-Tiny-Tokens-Embeddings-Plot.png\", bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD SEED MIDI)"
      ],
      "metadata": {
        "id": "Gt03VtO6uKkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Seed MIDI\n",
        "\n",
        "#@markdown Press play button to to upload your own seed MIDI\n",
        "\n",
        "number_of_prime_tokens = 300 # @param {type:\"slider\", min:30, max:5000, step:5}\n",
        "render_MIDI_to_audio = False # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Pentagram Music Transformer Seed MIDI Loader')\n",
        "print('=' * 70)\n",
        "\n",
        "f = ''\n",
        "\n",
        "print('Upload your own custom MIDI...')\n",
        "print('=' * 70)\n",
        "uploaded_MIDI = files.upload()\n",
        "if list(uploaded_MIDI.keys()):\n",
        "  score = TMIDIX.midi2single_track_ms_score(list(uploaded_MIDI.values())[0], recalculate_channels=False)\n",
        "  f = list(uploaded_MIDI.keys())[0]\n",
        "\n",
        "if f != '':\n",
        "\n",
        "  print('=' * 70)\n",
        "  print('File:', f)\n",
        "  print('=' * 70)\n",
        "\n",
        "  #=======================================================\n",
        "  # START PROCESSING\n",
        "\n",
        "  # INSTRUMENTS CONVERSION CYCLE\n",
        "\n",
        "  events_matrix = []\n",
        "  itrack = 1\n",
        "  patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "  while itrack < len(score):\n",
        "      for event in score[itrack]:\n",
        "          if event[0] == 'note' or event[0] == 'patch_change':\n",
        "              events_matrix.append(event)\n",
        "      itrack += 1\n",
        "\n",
        "  events_matrix.sort(key=lambda x: x[1])\n",
        "\n",
        "  events_matrix1 = []\n",
        "\n",
        "  for event in events_matrix:\n",
        "          if event[0] == 'patch_change':\n",
        "                patches[event[2]] = event[3]\n",
        "\n",
        "          if event[0] == 'note':\n",
        "                event.extend([patches[event[3]]])\n",
        "\n",
        "                events_matrix1.append(event)\n",
        "\n",
        "  if len(events_matrix1) > 0:\n",
        "    if min([e[1] for e in events_matrix1]) >= 0 and min([e[2] for e in events_matrix1]) >= 0:\n",
        "\n",
        "      #=======================================================\n",
        "      # PRE-PROCESSING\n",
        "\n",
        "      # checking number of instruments in a composition\n",
        "      instruments_list_without_drums = list(set([y[3] for y in events_matrix1 if y[3] != 9]))\n",
        "      instruments_list = list(set([y[3] for y in events_matrix1]))\n",
        "\n",
        "      if len(events_matrix1) > 0 and len(instruments_list_without_drums) > 0:\n",
        "\n",
        "        # recalculating timings\n",
        "        for e in events_matrix1:\n",
        "            e[1] = int(e[1] / 8) # Max 2 seconds for start-times\n",
        "            e[2] = int(e[2] / 16) # Max 4 seconds for durations\n",
        "\n",
        "        # Sorting by pitch, then by start-time\n",
        "        events_matrix1.sort(key=lambda x: x[4], reverse=True)\n",
        "        events_matrix1.sort(key=lambda x: x[1])\n",
        "\n",
        "        #=======================================================\n",
        "        # FINAL PRE-PROCESSING\n",
        "\n",
        "        melody_chords = []\n",
        "\n",
        "        pe = events_matrix1[0]\n",
        "\n",
        "        for e in events_matrix1:\n",
        "\n",
        "            # Cliping all values...\n",
        "            time = max(0, min(255, e[1]-pe[1]))\n",
        "            dur = max(0, min(255, e[2]))\n",
        "            cha = max(0, min(15, e[3]))\n",
        "            ptc = max(1, min(127, e[4]))\n",
        "\n",
        "            # Calculating octo-velocity\n",
        "            vel = max(1, min(127, e[5]))\n",
        "\n",
        "            pat = max(0, min(127, e[6]))\n",
        "\n",
        "            # Writing final note\n",
        "            melody_chords.append([time, dur, cha, ptc, vel, pat])\n",
        "\n",
        "            pe = e\n",
        "\n",
        "\n",
        "\n",
        "        #=======================================================\n",
        "        # FINAL PROCESSING\n",
        "        #=======================================================\n",
        "\n",
        "        melody_chords2 = []\n",
        "\n",
        "        # Break between compositions / Intro seq\n",
        "\n",
        "        if 9 in instruments_list:\n",
        "          drums_present = 1539 # Yes\n",
        "        else:\n",
        "          drums_present = 1538 # No\n",
        "\n",
        "        if melody_chords[0][2] != 9:\n",
        "            pat = melody_chords[0][5]\n",
        "        else:\n",
        "            pat = 128\n",
        "\n",
        "        melody_chords2.extend([1669, 1669, 1669, drums_present, 1540+pat])\n",
        "\n",
        "        #=======================================================\n",
        "\n",
        "        # TOTAL DICTIONARY SIZE 1669+1=1670\n",
        "\n",
        "        #=======================================================\n",
        "        # MAIN PROCESSING CYCLE\n",
        "        #=======================================================\n",
        "\n",
        "        note_counter = 1\n",
        "\n",
        "        for m in melody_chords:\n",
        "\n",
        "            if note_counter % 100 == 0:\n",
        "                nct = 1025+min(511, (note_counter // 100)) # note counter token\n",
        "                melody_chords2.extend([nct, nct, nct, nct, nct])\n",
        "\n",
        "            if m[2] != 9:\n",
        "                ptc = m[3]\n",
        "                pat = m[5]\n",
        "            else:\n",
        "                ptc = m[3] + 128\n",
        "                pat = 128\n",
        "\n",
        "            melody_chords2.extend([pat, m[0]+129, m[1]+385, ptc+641, m[4]+897])\n",
        "\n",
        "            note_counter += 1\n",
        "\n",
        "  melody_chords2 = melody_chords2[:number_of_prime_tokens]\n",
        "\n",
        "  #=======================================================\n",
        "\n",
        "  print('Composition stats:')\n",
        "  print('Composition has', len(melody_chords2) // 5, 'notes')\n",
        "  print('Composition has', len(melody_chords2), 'tokens')\n",
        "  print('=' * 70)\n",
        "\n",
        "  data = melody_chords2\n",
        "\n",
        "  print('Sample INTs:', data[:10])\n",
        "  print('=' * 70)\n",
        "\n",
        "  if len(data) != 0:\n",
        "\n",
        "      song = data\n",
        "      song_f = []\n",
        "      time = 0\n",
        "      dur = 0\n",
        "      vel = 90\n",
        "      pitch = 0\n",
        "      channel = 0\n",
        "\n",
        "      patches = [0] * 16\n",
        "\n",
        "      channels = [0] * 16\n",
        "      channels[9] = 1\n",
        "\n",
        "\n",
        "      for ss in song:\n",
        "\n",
        "        if ss >= 0 and ss <= 128:\n",
        "\n",
        "          if ss < 128:\n",
        "\n",
        "              if ss not in patches:\n",
        "                cha = channels.index(0)\n",
        "                channels[cha] = 1\n",
        "\n",
        "                patches[cha] = ss\n",
        "                channel = patches.index(ss)\n",
        "              else:\n",
        "                channel = patches.index(ss)\n",
        "\n",
        "          if ss == 128:\n",
        "              channel = 9\n",
        "\n",
        "        if ss > 128 and ss <= 256:\n",
        "\n",
        "          time += (ss-129) * 8\n",
        "\n",
        "        if ss > 384 and ss <= 640:\n",
        "\n",
        "          dur = (ss-385) * 16\n",
        "\n",
        "        if ss > 640 and ss <= 896:\n",
        "\n",
        "          pitch = (ss-641) % 128\n",
        "\n",
        "        if ss > 896 and ss <= 1024:\n",
        "\n",
        "          vel = (ss-897)\n",
        "\n",
        "          song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "      detailed_stats = TMIDIX.Tegridy_ms_SONG_to_MIDI_Converter(song_f,\n",
        "                                                                output_signature = 'Pentagram Music Transformer',\n",
        "                                                                output_file_name = '/content/Pentagram-Music-Transformer-Seed-Composition',\n",
        "                                                                track_name='Project Los Angeles',\n",
        "                                                                list_of_MIDI_patches=patches\n",
        "                                                                )\n",
        "      print('Done!')\n",
        "\n",
        "\n",
        "  print('=' * 70)\n",
        "  print('Displaying resulting composition...')\n",
        "  print('=' * 70)\n",
        "\n",
        "  fname = '/content/Pentagram-Music-Transformer-Seed-Composition'\n",
        "\n",
        "  x = []\n",
        "  y =[]\n",
        "  c = []\n",
        "\n",
        "  colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver', 'red', 'yellow', 'green', 'cyan']\n",
        "\n",
        "  block_lines = [(song_f[-1][1] / 1000)]\n",
        "  block_tokens = [min(len(melody_chords2), number_of_prime_tokens)]\n",
        "\n",
        "  for s in song_f:\n",
        "    x.append(s[1] / 1000)\n",
        "    y.append(s[4])\n",
        "    c.append(colors[s[3]])\n",
        "\n",
        "  if render_MIDI_to_audio:\n",
        "    FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "    display(Audio(str(fname + '.wav'), rate=16000))\n",
        "\n",
        "  plt.figure(figsize=(14,5))\n",
        "  ax=plt.axes(title=fname)\n",
        "  ax.set_facecolor('black')\n",
        "\n",
        "  plt.scatter(x,y, c=c)\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.ylabel(\"Pitch\")\n",
        "  plt.show()\n",
        "\n",
        "else:\n",
        "  print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XGQi15DfVU_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (COMPOSITION LOOP)\n",
        "\n",
        "## Run the cells below in a loop to generate endless continuation"
      ],
      "metadata": {
        "id": "7xNyANjZsCOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkvXYwR_qSnx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Standard Continuation Generator\n",
        "\n",
        "#@markdown Generation settings\n",
        "\n",
        "number_of_tokens_to_generate = 300 # @param {type:\"slider\", min:30, max:2000, step:5}\n",
        "number_of_batches_to_generate = 4 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "preview_length_in_tokens = 120 # @param {type:\"slider\", min:30, max:250, step:5}\n",
        "number_of_memory_tokens = 4095 # @param {type:\"slider\", min:400, max:4095, step:5}\n",
        "temperature = 0.9 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "\n",
        "#@markdown Other settings\n",
        "\n",
        "render_MIDI_to_audio = True # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Pentagram Music Transformer Standard Continuation Model Generator')\n",
        "print('=' * 70)\n",
        "\n",
        "preview = melody_chords2[-preview_length_in_tokens:]\n",
        "\n",
        "inp = [melody_chords2[-number_of_memory_tokens:]] * number_of_batches_to_generate\n",
        "\n",
        "inp = torch.LongTensor(inp).cuda()\n",
        "\n",
        "with ctx:\n",
        "  out = model.module.generate(inp,\n",
        "                              number_of_tokens_to_generate,\n",
        "                              temperature=temperature,\n",
        "                              return_prime=False,\n",
        "                              verbose=True)\n",
        "\n",
        "out0 = out.tolist()\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "\n",
        "#======================================================================\n",
        "print('=' * 70)\n",
        "print('Rendering results...')\n",
        "\n",
        "for i in range(number_of_batches_to_generate):\n",
        "\n",
        "  print('=' * 70)\n",
        "  print('Batch #', i)\n",
        "  print('=' * 70)\n",
        "\n",
        "  out1 = out0[i]\n",
        "\n",
        "  print('Sample INTs', out1[:10])\n",
        "  print('=' * 70)\n",
        "\n",
        "  if len(out) != 0:\n",
        "\n",
        "      song = preview + out1\n",
        "      song_f = []\n",
        "      time = 0\n",
        "      dur = 0\n",
        "      vel = 0\n",
        "      pitch = 0\n",
        "      channel = 0\n",
        "\n",
        "      patches = [0] * 16\n",
        "\n",
        "      channels = [0] * 16\n",
        "      channels[9] = 1\n",
        "\n",
        "\n",
        "      for ss in song:\n",
        "\n",
        "        if ss >= 0 and ss <= 128:\n",
        "\n",
        "          if ss < 128:\n",
        "\n",
        "              if ss not in patches:\n",
        "                cha = channels.index(0)\n",
        "                channels[cha] = 1\n",
        "\n",
        "                patches[cha] = ss\n",
        "                channel = patches.index(ss)\n",
        "              else:\n",
        "                channel = patches.index(ss)\n",
        "\n",
        "          if ss == 128:\n",
        "              channel = 9\n",
        "\n",
        "        if ss > 128 and ss <= 256:\n",
        "\n",
        "          time += (ss-129) * 8\n",
        "\n",
        "        if ss > 384 and ss <= 640:\n",
        "\n",
        "          dur = (ss-385) * 16\n",
        "\n",
        "        if ss > 640 and ss <= 896:\n",
        "\n",
        "          pitch = (ss-641) % 128\n",
        "\n",
        "        if ss > 896 and ss <= 1024:\n",
        "\n",
        "          vel = (ss-897)\n",
        "\n",
        "          song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "      detailed_stats = TMIDIX.Tegridy_ms_SONG_to_MIDI_Converter(song_f,\n",
        "                                                              output_signature = 'Pentagram Music Transformer',\n",
        "                                                              output_file_name = '/content/Pentagram-Music-Transformer-Composition_'+str(i),\n",
        "                                                              track_name='Project Los Angeles',\n",
        "                                                              list_of_MIDI_patches=patches\n",
        "                                                              )\n",
        "\n",
        "      print('=' * 70)\n",
        "      print('Displaying resulting composition...')\n",
        "      print('=' * 70)\n",
        "\n",
        "      fname = '/content/Pentagram-Music-Transformer-Composition_'+str(i)\n",
        "\n",
        "      x = []\n",
        "      y =[]\n",
        "      c = []\n",
        "\n",
        "      colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n",
        "\n",
        "      for s in song_f:\n",
        "        x.append(s[1] / 1000)\n",
        "        y.append(s[4])\n",
        "        c.append(colors[s[3]])\n",
        "\n",
        "      if render_MIDI_to_audio:\n",
        "        FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "        display(Audio(str(fname + '.wav'), rate=16000))\n",
        "\n",
        "      plt.figure(figsize=(14,5))\n",
        "      ax=plt.axes(title=fname)\n",
        "      ax.set_facecolor('black')\n",
        "\n",
        "      plt.scatter(x,y, c=c)\n",
        "\n",
        "      pbl = song_f[(int(preview_length_in_tokens / 5))][1] / 1000\n",
        "\n",
        "      ax.axvline(x=pbl, c='w')\n",
        "\n",
        "      plt.xlabel(\"Time\")\n",
        "      plt.ylabel(\"Pitch\")\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose one generated block to add to the composition\n",
        "block_action = \"add_last_generated_block\" #@param [\"add_last_generated_block\", \"remove_last_added_block\"]\n",
        "add_block_with_batch_number = 0 #@param {type:\"slider\", min:0, max:15, step:1}\n",
        "render_MIDI_to_audio = False # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "\n",
        "if block_action == 'add_last_generated_block':\n",
        "  melody_chords2.extend(out0[min(len(out0)-1, add_block_with_batch_number)])\n",
        "  print('Block added!')\n",
        "else:\n",
        "  if len(block_tokens) > 1:\n",
        "    melody_chords2 = melody_chords2[:(len(melody_chords2)-block_tokens[-1])]\n",
        "    print('Block removed!')\n",
        "  else:\n",
        "    print('Nothing to remove!!!')\n",
        "\n",
        "print('=' * 70)\n",
        "print('Composition now has', len(melody_chords2), 'tokens')\n",
        "\n",
        "print('=' * 70)\n",
        "print('Sample INTs', out1[:10])\n",
        "print('=' * 70)\n",
        "\n",
        "if len(melody_chords2) != 0:\n",
        "\n",
        "    song = melody_chords2\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "\n",
        "    patches = [0] * 16\n",
        "\n",
        "    channels = [0] * 16\n",
        "    channels[9] = 1\n",
        "\n",
        "\n",
        "    for ss in song:\n",
        "\n",
        "      if ss >= 0 and ss <= 128:\n",
        "\n",
        "        if ss < 128:\n",
        "\n",
        "            if ss not in patches:\n",
        "              cha = channels.index(0)\n",
        "              channels[cha] = 1\n",
        "\n",
        "              patches[cha] = ss\n",
        "              channel = patches.index(ss)\n",
        "            else:\n",
        "              channel = patches.index(ss)\n",
        "\n",
        "        if ss == 128:\n",
        "            channel = 9\n",
        "\n",
        "      if ss > 128 and ss <= 256:\n",
        "\n",
        "        time += (ss-129) * 8\n",
        "\n",
        "      if ss > 384 and ss <= 640:\n",
        "\n",
        "        dur = (ss-385) * 16\n",
        "\n",
        "      if ss > 640 and ss <= 896:\n",
        "\n",
        "        pitch = (ss-641) % 128\n",
        "\n",
        "      if ss > 896 and ss <= 1024:\n",
        "\n",
        "        vel = (ss-897)\n",
        "\n",
        "        song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_ms_SONG_to_MIDI_Converter(song_f,\n",
        "                                                              output_signature = 'Pentagram Music Transformer',\n",
        "                                                              output_file_name = '/content/Pentagram-Music-Transformer-Composition',\n",
        "                                                              track_name='Project Los Angeles',\n",
        "                                                              list_of_MIDI_patches=patches\n",
        "                                                              )\n",
        "\n",
        "    print('=' * 70)\n",
        "    print('Displaying resulting composition...')\n",
        "    print('=' * 70)\n",
        "\n",
        "    fname = '/content/Pentagram-Music-Transformer-Composition'\n",
        "\n",
        "    x = []\n",
        "    y =[]\n",
        "    c = []\n",
        "\n",
        "    colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n",
        "\n",
        "    if block_action == 'add_last_generated_block':\n",
        "      block_lines.append((song_f[-1][1] / 1000))\n",
        "      block_tokens.append(len(out0[min(len(out0)-1, add_block_with_batch_number)]))\n",
        "    else:\n",
        "      if len(block_tokens) > 1:\n",
        "        block_lines.pop()\n",
        "        block_tokens.pop()\n",
        "\n",
        "    for s in song_f:\n",
        "      x.append(s[1] / 1000)\n",
        "      y.append(s[4])\n",
        "      c.append(colors[s[3]])\n",
        "\n",
        "    if render_MIDI_to_audio:\n",
        "      FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "      display(Audio(str(fname + '.wav'), rate=16000))\n",
        "\n",
        "    plt.figure(figsize=(14,5))\n",
        "    ax=plt.axes(title=fname)\n",
        "    ax.set_facecolor('black')\n",
        "\n",
        "    plt.scatter(x,y, c=c)\n",
        "\n",
        "    for bl in block_lines:\n",
        "      ax.axvline(x=bl, c='w')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Pitch\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3YdlOR_9TdYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congrats! You did it! :)"
      ],
      "metadata": {
        "id": "eoWDEy6CwDr6"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}